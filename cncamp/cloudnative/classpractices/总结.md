云原生训练营二期
---

## 为什么学习云原生

### 云原生背后的诉求

- 产品快速迭代，更快的上线速度
- 系统的高可用，故障时能够自动恢复与回滚
- 快速解决问题，细致的故障探测和发现
- 避免雪崩，故障时能自动隔离
- 系统的弹性伸缩，简便快速的水平扩容
- 成本和业务敏捷性

### 其他

从2021年12月19日到2022年04月17日，不知不觉已经将近四个月了。

2018年4月到2019年4月一年的时间，使用k8s operator 思想的初始化阶段，通过 watch + informer 机制，可观测的感知 GUP 资源的变化，利用 k8s 提升资源利用率，但没有系统的学习。

## 准备

- 《Kubernetes in Action》中文版
- 极客时间张磊老师的《深入剖析Kubernetes》

## 学习方法

1. 观看孟老师的录播视频，学习每周的新知识。并跟着101项目的文档做一遍实验。
2. 总结知识，形成知识体系，方便以后复习。
3. 孟老师的101文档和助教老师的直播后的文档中，有拓展链接，花时间扩展阅读。
4. 遇到不明白的地方，多刷几次视频 
5. 每天坚持一定的时间阅读官方文档。

## 学习收获

### Go语言

- 深入了解了多线程相关的知识及使用场景：
    - channel、goroutine、context
    - syn包下的Mutex、RWMutex、WaitGroup、Once、Cond等
- Go语言采用了CSP模型进行线程间通信，可以和Actor模型做区分。 
- goroutine的GMP模型，调度器的调度过程。
- Go的内存分配原理和内存回收原理：
    - 小对象（小于32K）先从mcache申请，然后不够的话再从mcentral申请，还不够直接从mheap申请；大对象的话直接从mheap申请。并且将内存根据object的不同大小分成了不同的size class。
    - 连续的object叫做span，span又分成了两类，scan和no scan，提高垃圾回收的效率。 
    - Go语言的内存分配参考了TCMalloc，这样做的好处是分配小对象无锁化，减少内存分配时间。另外，内存分成不同的size class，减少了内存碎片问题。
- 垃圾回收的过程包括Sweep Termination、Mark、Mark Termination、Sweep、三色标记过程。
- 作为比较，Go语言的垃圾回收算法相对于Java少了好多，Java还有复制算法、标记整理算法、分代收集算法、以及G1和ZGC使用的增量垃圾回收算法等。

### 云原生

> 理念：以微服务的方式部署应用，每个应用都打包为自己的容器，并动态编排这些容器以优化资源利用。

> 云原生首先是一种基础设施，运行在其上的应用称为云原生应用，只有符合云原生设计哲学的应用架构才称为云原生应用架构。

> 云原生通过工具和方法减少更新导致的故障问题，保证服务的高可用。

#### 云原生的代表技术

- 容器
    - 虚拟化使用 Hypervisor 在硬件级别分离应用程序，为每个应用程序提供自己的操作系统。
    - 容器化在操作系统级别分离硬件程序，将应用与软件分离开，允许应用共享服务器的操作系统；但应用程序没有在服务器上物理隔离。
    - LXC(Linux Container) 更多侧重于容器运行环境的资源隔离和限制(类似于一个进程沙箱)，而没有涉及容器镜像打包技术。
    - Docker(Build, Ship and Run) 在 LXC 的基础上，规范并建设了一套镜像打包和运行机制，将应用程序和其所依赖的文件打包到同一个镜像文件中，从而使其在转移到任何运行 Docker 的机器中时都可以运行，并能保证在任何机器中该用户程序执行的环境都一样。
- 服务网格
- 微服务
    - 增加内聚性，减少了频繁的开会
    - 开发快速，职责单一
- 不可变基础设施
- 声明式 API
 
> 这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。

##### 容器、不可变基础设施和声明式API之间联系很紧密

###### 容器、不可变基础设施

容器技术的出现，尤其是镜像技术，将应用的部署过程以一个配置文件的形式声明出来，提高了可移植性，镜像可以很方便的在不同机器之间拷贝，并且保证了基础环境的一致性。
另外，应用的部署过程以文件的形式记录下来，方便了修改历史的追踪。并且通过这种声明的方式，开发同学不用了解应用部署背后的整个细节，只需要声明需要什么就行。

容器技术的原理主要包括Namespace、Cgroups、UFS等。
- Namespace主要解决了不同容器之间隔离性问题，包括uts、pid、mount、user、ipc、network等。
- Cgroups主要解决限制容器资源的问题，由各种子系统组成，如CPU、memory子系统等。
- 联合文件系统，将镜像分成了不同的层，便于复用各个层，减少了镜像的磁盘空间占用，减少容器启动时间等。
- 网络方面
  - 单机网络模式，例如None、host、container、bridge。
  - 不同主机之间的网络模式，主要有Underlay和Overlay两种方式。
  - Overlay又包括VXLAN、IPIP、GRE等。
- Dockerfile的最佳实践，采用比较小的基础镜像、多阶段构建、利用build cache等。

###### 声明式 API

声明式API打通了开发和运维的界限，开发同学只需要写好yaml文件，描述自己的desire，k8s集群会通过一个sync loop 来比较当前的status和desire之间的差异，通过控制平面和数据平面，达到期望结果。
- k8s控制平面主要包括APIServer、Controller Manager、Scheduler、etcd。
    - k8s和外部之间，以及k8s组件之间，和etcd的通信都是通过APIServer来进行。 APIServer采用REST的方式和外部通信。
    - Controller Manager负责集群达到预期的状态。
    - Scheduler负责将相应的作业调度到数据平面。
- k8s数据平面包括kubelet、kubeproxy、coredns等。
    - kubelet是执行者，负责执行控制平面下达的命令，并定期上报自己所在node以及node上pod的状态。
    - kubeproxy的作用是实现服务发现和负载均衡。

##### 其次，谈一下微服务和服务网格。

微服务的共性问题：

- 服务发布、服务发现、服务认证 
- 网关、路由和负载均衡、限流 
- 故障容错和降级、链路追踪、监控、灰度发布等
  
Istio将微服务的共性问题下沉到了基础设施上，开发人员只需专注开发业务逻辑。

- Gateway对象抽象了网关
- VirtualService对象抽象了服务发现、路由、故障容错、灰度发布
- DestinationRule对象抽象了负载均衡
- Peerauthentication、RequestAuthentication、AuthorizationPolicy三个对象抽象了认证和授权相关
- kiali实现了链路追踪、监控等功能

## 最后

k8s生态内容太多，部署应用的方方面面都考虑到了，任何一方面研究下去都有好多东西，需要选择一个自己感兴趣的方面，深入并坚持下去，不要丢了自驱力。

感谢孟老师以及各位助教老师有辛苦付出。